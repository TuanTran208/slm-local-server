models:
  - id: llama3-3b-q8
    name: Llama 3.2 3B Instruct Q8
    model_path: models/llama-3.2-3b-instruct-q8_0.gguf
    model_family: llama
    context_length: 8192
    local: true
    default_parameters:
      temperature: 0.7
      top_p: 0.95
      max_tokens: 2048
      repeat_penalty: 1.1
    provider_parameters:
      n_gpu_layers: -1  # -1: GPU , 0: only use CPU
      n_ctx: 8192
      use_mlock: false
      use_mmap: true
      
  - id: mistral-7b
    name: Mistral 7B Instruct
    model_path: models/mistral-7b-instruct-v0.2.Q4_K_M.gguf
    model_family: mistral
    context_length: 8192
    local: true
    default_parameters:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 2048
      repeat_penalty: 1.1
    provider_parameters:
      n_gpu_layers: -1
      n_ctx: 8192
      use_mlock: false
      use_mmap: true
